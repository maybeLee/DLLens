{
  "function_name": "tf.image.extract_patches(images,sizes,strides,rates,padding,name=None)",
  "inputs": [
    "images",
    "sizes",
    "strides",
    "rates",
    "padding"
  ],
  "sample_inputs": [
    "images = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)[None, :, :, None]\nsizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'",
    "images = tf.constant([[[[1]], [[2]], [[3]], [[4]]], [[[5]], [[6]], [[7]], [[8]]]], dtype=tf.float32)\nsizes = [1, 2, 2, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'",
    "sizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'\nimages = tf.constant(np.random.randn(1,3,3,1), dtype='float32')",
    "sizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'\nimages = tf.constant(np.random.randn(1,3,3,1), dtype='half')",
    "sizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'\nimages = tf.constant(np.random.randn(1,5,3,1), dtype='float32')",
    "sizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'\nimages = tf.constant(np.random.randn(1,3,3,1), dtype='float16')",
    "sizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'\nimages = tf.constant(np.random.randn(1,3,3,5), dtype='float32')",
    "sizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'\nimages = tf.constant(np.random.randn(4,3,3,1), dtype='float32')",
    "sizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'\nimages = tf.constant(np.random.randn(1,3,3,1), dtype='float64')",
    "sizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'\nimages = tf.constant(np.random.randn(1,1,3,1), dtype='float32')"
  ],
  "counterparts": {
    "tensorflow": "def tensorflow_call(images,sizes,strides,rates,padding):\n  return tf.image.extract_patches(images,sizes,strides,rates,padding)",
    "pytorch": "def pytorch_call(images, sizes, strides, rates, padding):\n    (batch_size, channels, height, width) = images.shape\n    kernel_size = sizes[1:3]\n    stride = strides[1:3]\n    if padding == 'VALID':\n        padding = 0\n    else:\n        padding = (sizes[1] // 2, sizes[2] // 2)\n    if kernel_size[0] > height or kernel_size[1] > width:\n        return torch.empty((0, channels * kernel_size[0] * kernel_size[1], 0))\n    patches = F.unfold(images, kernel_size=kernel_size, stride=stride, padding=padding)\n    return patches"
  },
  "llm_inputs": [
    "images = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)[None, :, :, None]\nsizes = [1, 1, 1, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'",
    "images = tf.constant([[[[1]], [[2]], [[3]], [[4]]], [[[5]], [[6]], [[7]], [[8]]]], dtype=tf.float32)\nsizes = [1, 2, 2, 1]\nstrides = [1, 1, 1, 1]\nrates = [1, 1, 1, 1]\npadding = 'VALID'"
  ]
}