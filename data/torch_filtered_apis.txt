torch.abs(input, *, out=None),
torch.absolute(input, *, out=None),
torch.acosh(input, *, out=None),
torch.acos(input, *, out=None),
torch.addbmm(input, batch1, batch2, *, beta=1, alpha=1, out=None),
torch.addcdiv(input, tensor1, tensor2, *, value=1, out=None),
torch.addcmul(input, tensor1, tensor2, *, value=1, out=None),
torch.add(input, other, *, alpha=1, out=None),
torch.addmm(input, mat1, mat2, *, beta=1, alpha=1, out=None),
torch.addmv(input, mat, vec, *, beta=1, alpha=1, out=None),
torch.addr(input, vec1, vec2, *, beta=1, alpha=1, out=None),
torch.allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False),
torch.all(input, dim, keepdim=False, *, out=None),
torch.amax(input, dim, keepdim=False, *, out=None),
torch.amin(input, dim, keepdim=False, *, out=None),
torch.aminmax(input, *, dim=None, keepdim=False, out=None),
torch.angle(input, *, out=None),
torch.any(input, dim, keepdim=False, *, out=None),
torch.arange(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.arccosh(input, *, out=None),
torch.arccos(input, *, out=None),
torch.arcsinh(input, *, out=None),
torch.arcsin(input, *, out=None),
torch.arctanh(input, *, out=None),
torch.arctan(input, *, out=None),
torch.argmax(input, dim, keepdim=False),
torch.argmin(input, dim=None, keepdim=False),
torch.argsort(input, dim=-1, descending=False),
torch.asinh(input, *, out=None),
torch.asin(input, *, out=None),
torch._assert(condition, message),
torch.as_strided(input, size, stride, storage_offset=0),
torch.as_tensor(data, dtype=None, device=None),
torch.atan2(input, other, *, out=None),
torch.atanh(input, *, out=None),
torch.atan(input, *, out=None),
torch.atleast_1d(*tensors),
torch.atleast_2d(*tensors),
torch.atleast_3d(*tensors),
torch.baddbmm(input, batch1, batch2, *, beta=1, alpha=1, out=None),
torch.bartlett_window(window_length, periodic=True, *, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.bernoulli(input, *, generator=None, out=None),
torch.bincount(input, weights=None, minlength=0),
torch.bitwise_and(input, other, *, out=None),
torch.bitwise_left_shift(input, other, *, out=None),
torch.bitwise_not(input, *, out=None),
torch.bitwise_or(input, other, *, out=None),
torch.bitwise_right_shift(input, other, *, out=None),
torch.bitwise_xor(input, other, *, out=None),
torch.blackman_window(window_length, periodic=True, *, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.block_diag(*tensors),
torch.bmm(input, mat2, *, deterministic=False, out=None),
torch.broadcast_shapes(*shapes),
torch.broadcast_tensors(*tensors),
torch.broadcast_to(input, shape),
torch.bucketize(input, boundaries, *, out_int32=False, right=False, out=None),
torch.can_cast(from, to),
torch.cartesian_prod(*tensors),
torch.cat(tensors, dim=0, *, out=None),
torch.cdist(x1, x2, p=2.0, compute_mode='use_mm_for_euclid_dist_if_necessary'),
torch.ceil(input, *, out=None),
torch.chain_matmul(*matrices, out=None),
torch.cholesky_inverse(input, upper=False, *, out=None),
torch.cholesky(input, upper=False, *, out=None),
torch.cholesky_solve(input, input2, upper=False, *, out=None),
torch.chunk(input, chunks, dim=0),
torch.clamp(input, min=None, max=None, *, out=None),
torch.clip(input, min=None, max=None, *, out=None),
torch.clone(input, *, memory_format=torch.preserve_format),
torch.column_stack(tensors, *, out=None),
torch.combinations(input, r=2, with_replacement=False),
torch.complex(real, imag, *, out=None),
torch.concat(tensors, dim=0, *, out=None),
torch.conj(input),
torch.conj_physical(input, *, out=None),
torch.copysign(input, other, *, out=None),
torch.corrcoef(input),
torch.cosh(input, *, out=None),
torch.cos(input, *, out=None),
torch.count_nonzero(input, dim=None),
torch.cov(input, *, correction=1, fweights=None, aweights=None),
torch.cross(input, other, dim=None, *, out=None),
torch.cummax(input, dim, *, out=None),
torch.cummin(input, dim, *, out=None),
torch.cumprod(input, dim, *, dtype=None, out=None),
torch.cumsum(input, dim, *, dtype=None, out=None),
torch.cumulative_trapezoid(y, x=None, *, dx=None, dim=-1),
torch.deg2rad(input, *, out=None),
torch.dequantize(tensor),
torch.det(input),
torch.diag_embed(input, offset=0, dim1=-2, dim2=-1),
torch.diagflat(input, offset=0),
torch.diag(input, diagonal=0, *, out=None),
torch.diagonal(input, offset=0, dim1=0, dim2=1),
torch.diff(input, n=1, dim=-1, prepend=None, append=None),
torch.digamma(input, *, out=None),
torch.dist(input, other, p=2),
torch.distributions.kl.kl_divergence(p, q),
torch.distributions.kl.register_kl(type_p, type_q),
torch.divide(input, other, *, rounding_mode=None, out=None),
torch.div(input, other, *, rounding_mode=None, out=None),
torch.dot(input, other, *, out=None),
torch.dsplit(input, indices_or_sections),
torch.dstack(tensors, *, out=None),
torch.eig(input, eigenvectors=False, *, out=None),
torch.einsum(equation, *operands),
torch.empty(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False, pin_memory=False, memory_format=torch.contiguous_format),
torch.empty_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format),
torch.empty_strided(size, stride, *, dtype=None, layout=None, device=None, requires_grad=False, pin_memory=False),
torch.eq(input, other, *, out=None),
torch.equal(input, other),
torch.erfc(input, *, out=None),
torch.erfinv(input, *, out=None),
torch.erf(input, *, out=None),
torch.exp2(input, *, out=None),
torch.exp(input, *, out=None),
torch.expm1(input, *, out=None),
torch.eye(n, m=None, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.fake_quantize_per_channel_affine(input, scale, zero_point, quant_min, quant_max),
torch.fake_quantize_per_tensor_affine(input, scale, zero_point, quant_min, quant_max),
torch.fft.fft2(input, s=None, dim=(-2, -1), norm=None, *, out=None),
torch.fft.fftfreq(n, d=1.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.fft.fft(input, n=None, dim=-1, norm=None, *, out=None),
torch.fft.fftn(input, s=None, dim=None, norm=None, *, out=None),
torch.fft.fftshift(input, dim=None),
torch.fft.hfft(input, n=None, dim=-1, norm=None, *, out=None),
torch.fft.ifft2(input, s=None, dim=(-2, -1), norm=None, *, out=None),
torch.fft.ifft(input, n=None, dim=-1, norm=None, *, out=None),
torch.fft.ifftn(input, s=None, dim=None, norm=None, *, out=None),
torch.fft.ifftshift(input, dim=None),
torch.fft.ihfft(input, n=None, dim=-1, norm=None, *, out=None),
torch.fft.irfft2(input, s=None, dim=(-2, -1), norm=None, *, out=None),
torch.fft.irfft(input, n=None, dim=-1, norm=None, *, out=None),
torch.fft.irfftn(input, s=None, dim=None, norm=None, *, out=None),
torch.fft.rfft2(input, s=None, dim=(-2, -1), norm=None, *, out=None),
torch.fft.rfftfreq(n, d=1.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.fft.rfft(input, n=None, dim=-1, norm=None, *, out=None),
torch.fft.rfftn(input, s=None, dim=None, norm=None, *, out=None),
torch.fix(input, *, out=None),
torch.flatten(input, start_dim=0, end_dim=-1),
torch.flip(input, dims),
torch.fliplr(input),
torch.flipud(input),
torch.float_power(input, exponent, *, out=None),
torch.floor_divide(input, other, *, out=None),
torch.floor(input, *, out=None),
torch.fmax(input, other, *, out=None),
torch.fmin(input, other, *, out=None),
torch.fmod(input, other, *, out=None),
torch.frac(input, *, out=None),
torch.frexp(input, *, out=None),
torch.frombuffer(buffer, *, dtype, count=-1, offset=0, requires_grad=False),
torch.from_numpy(ndarray),
torch.full(size, fill_value, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.full_like(input, fill_value, *, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format),
torch.gather(input, dim, index, *, sparse_grad=False, out=None),
torch.gcd(input, other, *, out=None),
torch.ge(input, other, *, out=None),
torch.geqrf(input, *, out=None),
torch.ger(input, vec2, *, out=None),
torch.gradient(input, *, spacing=1, dim=None, edge_order=1),
torch.greater_equal(input, other, *, out=None),
torch.greater(input, other, *, out=None),
torch.gt(input, other, *, out=None),
torch.hamming_window(window_length, periodic=True, alpha=0.54, beta=0.46, *, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.hann_window(window_length, periodic=True, *, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.heaviside(input, values, *, out=None),
torch.histc(input, bins=100, min=0, max=0, *, out=None),
torch.histogram(input, bins, *, range=None, weight=None, density=False, out=None),
torch.hsplit(input, indices_or_sections),
torch.hspmm(mat1, mat2, *, out=None),
torch.hstack(tensors, *, out=None),
torch.hypot(input, other, *, out=None),
torch.i0(input, *, out=None),
torch.igammac(input, other, *, out=None),
torch.igamma(input, other, *, out=None),
torch.imag(input),
torch.index_select(input, dim, index, *, out=None),
torch.inference_mode(mode=True),
torch.inner(input, other, *, out=None),
torch.inverse(input, *, out=None),
torch.isclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False),
torch.is_complex(input),
torch.is_conj(input),
torch.isfinite(input),
torch.is_floating_point(input),
torch.isinf(input),
torch.isin(elements, test_elements, *, assume_unique=False, invert=False),
torch.isnan(input),
torch.isneginf(input, *, out=None),
torch.is_nonzero(input),
torch.isposinf(input, *, out=None),
torch.isreal(input),
torch.is_storage(obj),
torch.is_tensor(obj),
torch.istft(input, n_fft, hop_length=None, win_length=None, window=None, center=True, normalized=False, onesided=None, length=None, return_complex=False),
torch.kaiser_window(window_length, periodic=True, beta=12.0, *, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.kron(input, other, *, out=None),
torch.kthvalue(input, k, dim=None, keepdim=False, *, out=None),
torch.lcm(input, other, *, out=None),
torch.ldexp(input, other, *, out=None),
torch.le(input, other, *, out=None),
torch.lerp(input, end, weight, *, out=None),
torch.less_equal(input, other, *, out=None),
torch.less(input, other, *, out=None),
torch.lgamma(input, *, out=None),
torch.linalg.cholesky_ex(A, *, upper=False, check_errors=False, out=None),
torch.linalg.cholesky(A, *, upper=False, out=None),
torch.linalg.cond(A, p=None, *, out=None),
torch.linalg.det(A, *, out=None),
torch.linalg.eigh(A, UPLO='L', *, out=None),
torch.linalg.eig(A, *, out=None),
torch.linalg.eigvalsh(A, UPLO='L', *, out=None),
torch.linalg.eigvals(A, *, out=None),
torch.linalg.householder_product(A, tau, *, out=None),
torch.linalg.inv_ex(A, *, check_errors=False, out=None),
torch.linalg.inv(A, *, out=None),
torch.linalg.lstsq(A, B, rcond=None, *, driver=None),
torch.linalg.matmul(input, other, *, out=None),
torch.linalg.matrix_norm(A, ord='fro', dim=(-2, -1), keepdim=False, *, dtype=None, out=None),
torch.linalg.matrix_power(A, n, *, out=None),
torch.linalg.matrix_rank(A, tol=None, hermitian=False, *, out=None),
torch.linalg.multi_dot(tensors, *, out=None),
torch.linalg.norm(A, ord=None, dim=None, keepdim=False, *, out=None, dtype=None),
torch.linalg.pinv(A, rcond=1e-15, hermitian=False, *, out=None),
torch.linalg.qr(A, mode='reduced', *, out=None),
torch.linalg.slogdet(A, *, out=None),
torch.linalg.solve(A, B, *, out=None),
torch.linalg.svd(A, full_matrices=True, *, out=None),
torch.linalg.svdvals(A, *, out=None),
torch.linalg.tensorinv(A, ind=2, *, out=None),
torch.linalg.tensorsolve(A, B, dims=None, *, out=None),
torch.linalg.vector_norm(A, ord=2, dim=None, keepdim=False, *, dtype=None, out=None),
torch.linspace(start, end, steps, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.load(f, map_location=None, pickle_module=pickle, *, weights_only=False, mmap=None, **pickle_load_args),
torch.lobpcg(A, k=None, B=None, X=None, n=None, iK=None, niter=None, tol=None, largest=None, method=None, tracker=None, ortho_iparams=None, ortho_fparams=None, ortho_bparams=None),
torch.log10(input, *, out=None),
torch.log1p(input, *, out=None),
torch.log2(input, *, out=None),
torch.logaddexp2(input, other, *, out=None),
torch.logaddexp(input, other, *, out=None),
torch.logcumsumexp(input, dim, *, out=None),
torch.logdet(input),
torch.logical_and(input, other, *, out=None),
torch.logical_not(input, *, out=None),
torch.logical_or(input, other, *, out=None),
torch.logical_xor(input, other, *, out=None),
torch.logit(input, eps=None, *, out=None),
torch.log(input, *, out=None),
torch.logspace(start, end, steps, base=10.0, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.logsumexp(input, dim, keepdim=False, *, out=None),
torch.lstsq(input, A, *, out=None),
torch.lt(input, other, *, out=None),
torch.lu(A, pivot=True, get_infos=False, *, out=None),
torch.lu_solve(b, LU_data, LU_pivots, *, out=None),
torch.lu_unpack(LU_data, LU_pivots, unpack_data=True, unpack_pivots=True, *, out=None),
torch.manual_seed(seed),
torch.masked_select(input, mask, *, out=None),
torch.matmul(input, other, *, out=None),
torch.matrix_exp(input),
torch.matrix_power(input, n, *, out=None),
torch.matrix_rank(input, tol=None, symmetric=False, *, out=None),
torch.maximum(input, other, *, out=None),
torch.max(input, dim, keepdim=False, *, out=None),
torch.mean(input, dim, keepdim=False, *, dtype=None),
torch.median(input, dim=-1, keepdim=False, *, out=None),
torch.meshgrid(*tensors),
torch.minimum(input, other, *, out=None),
torch.min(input, dim, keepdim=False, *, out=None),
torch.mm(input, mat2, *, out=None),
torch.mode(input, dim=-1, keepdim=False, *, out=None),
torch.moveaxis(input, source, destination),
torch.movedim(input, source, destination),
torch.msort(input, *, out=None),
torch.mul(input, other, *, out=None),
torch.multinomial(input, num_samples, replacement=False, *, generator=None, out=None),
torch.multiply(input, other, *, out=None),
torch.mv(input, vec, *, out=None),
torch.mvlgamma(input, p),
torch.nanmean(input, dim=None, keepdim=False, *, dtype=None, out=None),
torch.nanmedian(input, dim=-1, keepdim=False, *, out=None),
torch.nanquantile(input, q, dim=None, keepdim=False, *, out=None),
torch.nansum(input, dim, keepdim=False, *, dtype=None),
torch.nan_to_num(input, nan=0.0, posinf=None, neginf=None, *, out=None),
torch.narrow(input, dim, start, length),
torch.negative(input, *, out=None),
torch.neg(input, *, out=None),
torch.ne(input, other, *, out=None),
torch.nextafter(input, other, *, out=None),
torch.nn.functional.adaptive_avg_pool1d(input, output_size),
torch.nn.functional.adaptive_avg_pool2d(input, output_size),
torch.nn.functional.adaptive_avg_pool3d(input, output_size),
torch.nn.functional.adaptive_max_pool1d(input, output_size, return_indices=False),
torch.nn.functional.adaptive_max_pool2d(input, output_size, return_indices=False),
torch.nn.functional.adaptive_max_pool3d(input, output_size, return_indices=False),
torch.nn.functional.affine_grid(theta, size, align_corners=None),
torch.nn.functional.alpha_dropout(input, p=0.5, training=False, inplace=False),
torch.nn.functional.avg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True),
torch.nn.functional.avg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None),
torch.nn.functional.avg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None),
torch.nn.functional.batch_norm(input, running_mean, running_var, weight=None, bias=None, training=False, momentum=0.1, eps=1e-05),
torch.nn.functional.bilinear(input1, input2, weight, bias=None),
torch.nn.functional.binary_cross_entropy(input, target, weight=None, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.binary_cross_entropy_with_logits(input, target, weight=None, size_average=None, reduce=None, reduction='mean', pos_weight=None),
torch.nn.functional.celu(input, alpha=1., inplace=False),
torch.nn.functional.conv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1),
torch.nn.functional.conv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1),
torch.nn.functional.conv3d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1),
torch.nn.functional.conv_transpose1d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1),
torch.nn.functional.conv_transpose2d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1),
torch.nn.functional.conv_transpose3d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1),
torch.nn.functional.cosine_embedding_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.cosine_similarity(x1, x2, dim=1, eps=1e-8),
torch.nn.functional.cross_entropy(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean'),
torch.nn.functional.ctc_loss(log_probs, targets, input_lengths, target_lengths, blank=0, reduction='mean', zero_infinity=False),
torch.nn.functional.dropout2d(input, p=0.5, training=True, inplace=False),
torch.nn.functional.dropout3d(input, p=0.5, training=True, inplace=False),
torch.nn.functional.dropout(input, p=0.5, training=True, inplace=False),
torch.nn.functional.elu_(input, alpha=1.),
torch.nn.functional.elu(input, alpha=1.0, inplace=False),
torch.nn.functional.embedding_bag(input, weight, offsets=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, mode='mean', sparse=False, per_sample_weights=None, include_last_offset=False, padding_idx=None),
torch.nn.functional.embedding(input, weight, padding_idx=None, max_norm=None, norm_type=2.0, scale_grad_by_freq=False, sparse=False),
torch.nn.functional.feature_alpha_dropout(input, p=0.5, training=False, inplace=False),
torch.nn.functional.fold(input, output_size, kernel_size, dilation=1, padding=0, stride=1),
torch.nn.functional.gaussian_nll_loss(input, target, var, full=False, eps=1e-06, reduction='mean'),
torch.nn.functional.gelu(input),
torch.nn.functional.glu(input, dim=-1),
torch.nn.functional.grid_sample(input, grid, mode='bilinear', padding_mode='zeros', align_corners=None),
torch.nn.functional.group_norm(input, num_groups, weight=None, bias=None, eps=1e-05),
torch.nn.functional.gumbel_softmax(logits, tau=1, hard=False, eps=1e-10, dim=-1),
torch.nn.functional.hardshrink(input, lambd=0.5),
torch.nn.functional.hardsigmoid(input, inplace=False),
torch.nn.functional.hardswish(input, inplace=False),
torch.nn.functional.hardtanh_(input, min_val=-1., max_val=1.),
torch.nn.functional.hardtanh(input, min_val=-1., max_val=1., inplace=False),
torch.nn.functional.hinge_embedding_loss(input, target, margin=1.0, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.huber_loss(input, target, reduction='mean', delta=1.0),
torch.nn.functional.instance_norm(input, running_mean=None, running_var=None, weight=None, bias=None, use_input_stats=True, momentum=0.1, eps=1e-05),
torch.nn.functional.interpolate(input, size=None, scale_factor=None, mode='nearest', align_corners=None, recompute_scale_factor=None),
torch.nn.functional.kl_div(input, target, size_average=None, reduce=None, reduction='mean', log_target=False),
torch.nn.functional.l1_loss(input, target, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.layer_norm(input, normalized_shape, weight=None, bias=None, eps=1e-05),
torch.nn.functional.leaky_relu_(input, negative_slope=0.01),
torch.nn.functional.leaky_relu(input, negative_slope=0.01, inplace=False),
torch.nn.functional.linear(input, weight, bias=None),
torch.nn.functional.local_response_norm(input, size, alpha=0.0001, beta=0.75, k=1.0),
torch.nn.functional.logsigmoid(input),
torch.nn.functional.log_softmax(input, dim=None, _stacklevel=3, dtype=None),
torch.nn.functional.lp_pool1d(input, norm_type, kernel_size, stride=None, ceil_mode=False),
torch.nn.functional.lp_pool2d(input, norm_type, kernel_size, stride=None, ceil_mode=False),
torch.nn.functional.margin_ranking_loss(input1, input2, target, margin=0, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.max_pool1d(input, kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False),
torch.nn.functional.max_pool2d(input, kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False),
torch.nn.functional.max_pool3d(input, kernel_size, stride=None, padding=0, dilation=1, return_indices=False, ceil_mode=False),
torch.nn.functional.max_unpool1d(input, indices, kernel_size, stride=None, padding=0, output_size=None),
torch.nn.functional.max_unpool2d(input, indices, kernel_size, stride=None, padding=0, output_size=None),
torch.nn.functional.max_unpool3d(input, indices, kernel_size, stride=None, padding=0, output_size=None),
torch.nn.functional.mish(input, inplace=False),
torch.nn.functional.mse_loss(input, target, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.multilabel_margin_loss(input, target, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.multilabel_soft_margin_loss(input, target, weight=None, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.multi_margin_loss(input, target, p=1, margin=1.0, weight=None, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.nll_loss(input, target, weight=None, size_average=None, ignore_index=-100, reduce=None, reduction='mean'),
torch.nn.functional.normalize(input, p=2.0, dim=1, eps=1e-12, out=None),
torch.nn.functional.one_hot(tensor, num_classes=-1),
torch.nn.functional.pad(input, pad, mode='constant', value=0),
torch.nn.functional.pairwise_distance(x1, x2, p=2.0, eps=1e-06, keepdim=False),
torch.nn.functional.pdist(input, p=2),
torch.nn.functional.pixel_shuffle(input, upscale_factor),
torch.nn.functional.pixel_unshuffle(input, downscale_factor),
torch.nn.functional.poisson_nll_loss(input, target, log_input=True, full=False, size_average=None, eps=1e-08, reduce=None, reduction='mean'),
torch.nn.functional.prelu(input, weight),
torch.nn.functional.relu6(input, inplace=False),
torch.nn.functional.relu_(input),
torch.nn.functional.relu(input, inplace=False),
torch.nn.functional.rrelu_(input, lower=1./8, upper=1./3, training=False),
torch.nn.functional.rrelu(input, lower=1./8, upper=1./3, training=False, inplace=False),
torch.nn.functional.selu(input, inplace=False),
torch.nn.functional.sigmoid(input),
torch.nn.functional.silu(input, inplace=False),
torch.nn.functional.smooth_l1_loss(input, target, size_average=None, reduce=None, reduction='mean', beta=1.0),
torch.nn.functional.soft_margin_loss(input, target, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.softmax(input, dim=None, _stacklevel=3, dtype=None),
torch.nn.functional.softmin(input, dim=None, _stacklevel=3, dtype=None),
torch.nn.functional.softplus(input, beta=1, threshold=20),
torch.nn.functional.softshrink(input, lambd=0.5),
torch.nn.functional.softsign(input),
torch.nn.functional.tanh(input),
torch.nn.functional.tanhshrink(input),
torch.nn.functional.threshold_(input, threshold, value),
torch.nn.functional.threshold(input, threshold, value, inplace=False),
torch.nn.functional.triplet_margin_loss(anchor, positive, negative, margin=1.0, p=2, eps=1e-06, swap=False, size_average=None, reduce=None, reduction='mean'),
torch.nn.functional.triplet_margin_with_distance_loss(anchor, positive, negative, *, distance_function=None, margin=1.0, swap=False, reduction='mean'),
torch.nn.functional.unfold(input, kernel_size, dilation=1, padding=0, stride=1),
torch.nn.functional.upsample_bilinear(input, size=None, scale_factor=None),
torch.nn.functional.upsample(input, size=None, scale_factor=None, mode='nearest', align_corners=None),
torch.nn.functional.upsample_nearest(input, size=None, scale_factor=None),
torch.nn.init.calculate_gain(nonlinearity, param=None),
torch.nn.init.constant_(tensor, val),
torch.nn.init.dirac_(tensor, groups=1),
torch.nn.init.eye_(tensor),
torch.nn.init.kaiming_normal_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu'),
torch.nn.init.kaiming_uniform_(tensor, a=0, mode='fan_in', nonlinearity='leaky_relu'),
torch.nn.init.normal_(tensor, mean=0.0, std=1.0),
torch.nn.init.ones_(tensor),
torch.nn.init.orthogonal_(tensor, gain=1),
torch.nn.init.sparse_(tensor, sparsity, std=0.01),
torch.nn.init.uniform_(tensor, a=0.0, b=1.0),
torch.nn.init.xavier_normal_(tensor, gain=1.0),
torch.nn.init.xavier_uniform_(tensor, gain=1.0),
torch.nn.init.zeros_(tensor),
torch.nn.modules.module.register_module_backward_hook(hook),
torch.nn.modules.module.register_module_forward_hook(hook),
torch.nn.modules.module.register_module_forward_pre_hook(hook),
torch.nn.modules.module.register_module_full_backward_hook(hook),
torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=2.0, error_if_nonfinite=False),
torch.nn.utils.clip_grad_value_(parameters, clip_value),
torch.nn.utils.parameters_to_vector(parameters),
torch.nn.utils.parametrizations.orthogonal(module, name='weight', orthogonal_map=None, *, use_trivialization=True),
torch.nn.utils.parametrizations.spectral_norm(module, name='weight', n_power_iterations=1, eps=1e-12, dim=None),
torch.nn.utils.parametrize.is_parametrized(module, tensor_name=None),
torch.nn.utils.parametrize.register_parametrization(module, tensor_name, parametrization, *, unsafe=False),
torch.nn.utils.parametrize.remove_parametrizations(module, tensor_name, leave_parametrized=True),
torch.nn.utils.prune.custom_from_mask(module, name, mask),
torch.nn.utils.prune.global_unstructured(parameters, pruning_method, importance_scores=None, **kwargs),
torch.nn.utils.prune.is_pruned(module),
torch.nn.utils.prune.l1_unstructured(module, name, amount, importance_scores=None),
torch.nn.utils.prune.ln_structured(module, name, amount, n, dim, importance_scores=None),
torch.nn.utils.prune.random_structured(module, name, amount, dim),
torch.nn.utils.prune.random_unstructured(module, name, amount),
torch.nn.utils.prune.remove(module, name),
torch.nn.utils.remove_spectral_norm(module, name='weight'),
torch.nn.utils.remove_weight_norm(module, name='weight'),
torch.nn.utils.rnn.pack_padded_sequence(input, lengths, batch_first=False, enforce_sorted=True),
torch.nn.utils.rnn.pack_sequence(sequences, enforce_sorted=True),
torch.nn.utils.rnn.pad_packed_sequence(sequence, batch_first=False, padding_value=0.0, total_length=None),
torch.nn.utils.rnn.pad_sequence(sequences, batch_first=False, padding_value=0.0),
torch.nn.utils.skip_init(module_cls, *args, **kwargs),
torch.nn.utils.spectral_norm(module, name='weight', n_power_iterations=1, eps=1e-12, dim=None),
torch.nn.utils.vector_to_parameters(vec, parameters),
torch.nn.utils.weight_norm(module, name='weight', dim=0),
torch.nonzero(input, *, out=None, as_tuple=False),
torch.normal(mean, std, size, *, out=None),
torch.norm(input, p='fro', dim=None, keepdim=False, out=None, dtype=None),
torch.not_equal(input, other, *, out=None),
torch.numel(input),
torch.ones(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.ones_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format),
torch.onnx.register_custom_op_symbolic(symbolic_name, symbolic_fn, opset_version),
torch.onnx.select_model_mode_for_export(model, mode),
torch.orgqr(input, tau),
torch.ormqr(input, tau, other, left=True, transpose=False, *, out=None),
torch.outer(input, vec2, *, out=None),
torch.overrides.handle_torch_function(public_api, relevant_args, *args, **kwargs),
torch.overrides.is_tensor_like(inp),
torch.overrides.is_tensor_method_or_property(func),
torch.overrides.wrap_torch_function(dispatcher),
torch.pca_lowrank(A, q=None, center=True, niter=2),
torch.permute(input, dims),
torch.pinverse(input, rcond=1e-15),
torch.poisson(input, generator=None),
torch.polar(abs, angle, *, out=None),
torch.polygamma(n, input, *, out=None),
torch.positive(input),
torch.pow(input, exponent, *, out=None),
torch.prod(input, dim, keepdim=False, *, dtype=None),
torch.profiler.tensorboard_trace_handler(dir_name, worker_name=None, use_gzip=False),
torch.promote_types(type1, type2),
torch.qr(input, some=True, *, out=None),
torch.quantile(input, q, dim=None, keepdim=False, *, out=None),
torch.quantized_batch_norm(input, weight=None, bias=None, mean, var, eps, output_scale, output_zero_point),
torch.quantized_max_pool1d(input, kernel_size, stride=[], padding=0, dilation=1, ceil_mode=False),
torch.quantized_max_pool2d(input, kernel_size, stride=[], padding=0, dilation=1, ceil_mode=False),
torch.quantize_per_channel(input, scales, zero_points, axis, dtype),
torch.quantize_per_tensor(input, scale, zero_point, dtype),
torch.rad2deg(input, *, out=None),
torch.randint(low=0, high, size, *, generator=None, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.randint_like(input, low=0, high, *, dtype=None, layout=torch.strided, device=None, requires_grad=False, memory_format=torch.preserve_format),
torch.rand(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.rand_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format),
torch.randn(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.randn_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format),
torch.random.fork_rng(devices=None, enabled=True, _caller='fork_rng', _devices_kw='devices'),
torch.random.manual_seed(seed),
torch.random.set_rng_state(new_state),
torch.randperm(n, *, generator=None, out=None, dtype=torch.int64, layout=torch.strided, device=None, requires_grad=False, pin_memory=False),
torch.range(start=0, end, step=1, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.ravel(input),
torch.real(input),
torch.reciprocal(input, *, out=None),
torch.remainder(input, other, *, out=None),
torch.renorm(input, p, dim, maxnorm, *, out=None),
torch.repeat_interleave(input, repeats, dim=None),
torch.reshape(input, shape),
torch.resolve_conj(input),
torch.resolve_neg(input),
torch.result_type(tensor1, tensor2),
torch.roll(input, shifts, dims=None),
torch.rot90(input, k, dims),
torch.round(input, *, out=None),
torch.row_stack(tensors, *, out=None),
torch.rsqrt(input, *, out=None),
torch.save(obj, f, pickle_module=pickle, pickle_protocol=DEFAULT_PROTOCOL, _use_new_zipfile_serialization=True),
torch.scatter_add(input, dim, index, src),
torch.scatter(input, dim, index, src),
torch.searchsorted(sorted_sequence, values, *, out_int32=False, right=False, out=None),
torch.set_default_dtype(d),
torch.set_default_tensor_type(t),
torch.set_flush_denormal(mode),
torch.set_grad_enabled(mode),
torch.set_num_interop_threads(int),
torch.set_num_threads(int),
torch.set_printoptions(precision=None, threshold=None, edgeitems=None, linewidth=None, profile=None, sci_mode=None),
torch.set_rng_state(new_state),
torch.set_warn_always(b),
torch.sgn(input, *, out=None),
torch.sigmoid(input, *, out=None),
torch.signbit(input, *, out=None),
torch.sign(input, *, out=None),
torch.sinc(input, *, out=None),
torch.sinh(input, *, out=None),
torch.sin(input, *, out=None),
torch.slogdet(input),
torch.smm(input, mat),
torch.solve(input, A, *, out=None),
torch.sort(input, dim=-1, descending=False, stable=False, *, out=None),
torch.sparse.addmm(mat, mat1, mat2, beta=1.0, alpha=1.0),
torch.sparse_coo_tensor(indices, values, size=None, *, dtype=None, device=None, requires_grad=False),
torch.sparse_csr_tensor(crow_indices, col_indices, values, size=None, *, dtype=None, device=None, requires_grad=False),
torch.sparse.log_softmax(input, dim, dtype=None),
torch.sparse.mm(mat1, mat2),
torch.sparse.softmax(input, dim, dtype=None),
torch.sparse.sum(input, dim=None, dtype=None),
torch.special.digamma(input, *, out=None),
torch.special.entr(input, *, out=None),
torch.special.erfc(input, *, out=None),
torch.special.erfcx(input, *, out=None),
torch.special.erfinv(input, *, out=None),
torch.special.erf(input, *, out=None),
torch.special.exp2(input, *, out=None),
torch.special.expit(input, *, out=None),
torch.special.expm1(input, *, out=None),
torch.special.gammaincc(input, other, *, out=None),
torch.special.gammainc(input, other, *, out=None),
torch.special.gammaln(input, *, out=None),
torch.special.i0e(input, *, out=None),
torch.special.i0(input, *, out=None),
torch.special.i1e(input, *, out=None),
torch.special.i1(input, *, out=None),
torch.special.log1p(input, *, out=None),
torch.special.logit(input, eps=None, *, out=None),
torch.special.log_softmax(input, dim, *, dtype=None),
torch.special.logsumexp(input, dim, keepdim=False, *, out=None),
torch.special.multigammaln(input, p, *, out=None),
torch.special.ndtri(input, *, out=None),
torch.special.ndtr(input, *, out=None),
torch.special.polygamma(n, input, *, out=None),
torch.special.psi(input, *, out=None),
torch.special.round(input, *, out=None),
torch.special.sinc(input, *, out=None),
torch.special.xlog1py(input, other, *, out=None),
torch.special.xlogy(input, other, *, out=None),
torch.special.zeta(input, other, *, out=None),
torch.split(tensor, split_size_or_sections, dim=0),
torch.sqrt(input, *, out=None),
torch.square(input, *, out=None),
torch.squeeze(input, dim=None, *, out=None),
torch.sspaddmm(input, mat1, mat2, *, beta=1, alpha=1, out=None),
torch.stack(tensors, dim=0, *, out=None),
torch.std(input, dim, unbiased, keepdim=False, *, out=None),
torch.std_mean(input, dim, unbiased, keepdim=False, *, out=None),
torch.stft(input, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=None, return_complex=None),
torch.sub(input, other, *, alpha=1, out=None),
torch.subtract(input, other, *, alpha=1, out=None),
torch.sum(input, dim, keepdim=False, *, dtype=None),
torch.svd(input, some=True, compute_uv=True, *, out=None),
torch.svd_lowrank(A, q=6, niter=2, M=None),
torch.swapaxes(input, axis0, axis1),
torch.swapdims(input, dim0, dim1),
torch.symeig(input, eigenvectors=False, upper=True, *, out=None),
torch.take_along_dim(input, indices, dim, *, out=None),
torch.take(input, index),
torch.tanh(input, *, out=None),
torch.tan(input, *, out=None),
torch.Tensor.abs_(input),
torch.Tensor.abs(input),
torch.Tensor.absolute_(input),
torch.Tensor.absolute(input),
torch.Tensor.acosh_(input),
torch.Tensor.acosh(input),
torch.Tensor.acos_(input),
torch.Tensor.acos(input),
torch.Tensor.addbmm_(input, batch1, batch2, *, beta=1, alpha=1),
torch.Tensor.addbmm(input, batch1, batch2, *, beta=1, alpha=1),
torch.Tensor.addcdiv_(input, tensor1, tensor2, *, value=1),
torch.Tensor.addcdiv(input, tensor1, tensor2, *, value=1),
torch.Tensor.addcmul_(input, tensor1, tensor2, *, value=1),
torch.Tensor.addcmul(input, tensor1, tensor2, *, value=1),
torch.Tensor.add_(input, other, *, alpha=1),
torch.Tensor.add(input, other, *, alpha=1),
torch.Tensor.addmm_(input, mat1, mat2, *, beta=1, alpha=1),
torch.Tensor.addmm(input, mat1, mat2, *, beta=1, alpha=1),
torch.Tensor.addmv_(input, mat, vec, *, beta=1, alpha=1),
torch.Tensor.addmv(input, mat, vec, *, beta=1, alpha=1),
torch.Tensor.addr_(input, vec1, vec2, *, beta=1, alpha=1),
torch.Tensor.addr(input, vec1, vec2, *, beta=1, alpha=1),
torch.Tensor.allclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False),
torch.Tensor.all(input, dim=None, keepdim=False),
torch.Tensor.amax(input, dim=None, keepdim=False),
torch.Tensor.amin(input, dim=None, keepdim=False),
torch.Tensor.aminmax(input, *, dim=None, keepdim=False),
torch.Tensor.angle(input),
torch.Tensor.any(input, dim=None, keepdim=False),
torch.Tensor.apply_(input, callable),
torch.Tensor.arccosh_(input, ),
torch.Tensor.arccosh(input),
torch.Tensor.arccos_(input),
torch.Tensor.arccos(input),
torch.Tensor.arcsinh_(input),
torch.Tensor.arcsinh(input),
torch.Tensor.arcsin_(input),
torch.Tensor.arcsin(input),
torch.Tensor.arctanh_(input, other),
torch.Tensor.arctanh(input),
torch.Tensor.arctan_(input),
torch.Tensor.arctan(input),
torch.Tensor.argmax(input, dim=None, keepdim=False),
torch.Tensor.argmin(input, dim=None, keepdim=False),
torch.Tensor.argsort(input, dim=-1, descending=False),
torch.Tensor.asinh_(input),
torch.Tensor.asinh(input),
torch.Tensor.asin_(input),
torch.Tensor.asin(input),
torch.Tensor.as_strided(input, size, stride, storage_offset=0),
torch.Tensor.as_subclass(input, cls),
torch.Tensor.atan2_(input, other),
torch.Tensor.atan2(input, other),
torch.Tensor.atanh_(input, other),
torch.Tensor.atanh(input),
torch.Tensor.atan_(input),
torch.Tensor.atan(input),
torch.Tensor.backward(input, gradient=None, retain_graph=None, create_graph=False, inputs=None),
torch.Tensor.baddbmm_(input, batch1, batch2, *, beta=1, alpha=1),
torch.Tensor.baddbmm(input, batch1, batch2, *, beta=1, alpha=1),
torch.Tensor.bernoulli_(input, p=0.5, *, generator=None),
torch.Tensor.bernoulli(input, *, generator=None),
torch.Tensor.bfloat16(input, memory_format=torch.preserve_format),
torch.Tensor.bincount(input, weights=None, minlength=0),
torch.Tensor.bitwise_and_(input, other),
torch.Tensor.bitwise_and(input, other),
torch.Tensor.bitwise_left_shift_(input, other),
torch.Tensor.bitwise_left_shift(input, other),
torch.Tensor.bitwise_not_(input),
torch.Tensor.bitwise_not(input),
torch.Tensor.bitwise_or_(input, other),
torch.Tensor.bitwise_or(input, other),
torch.Tensor.bitwise_right_shift_(input, other),
torch.Tensor.bitwise_right_shift(input, other),
torch.Tensor.bitwise_xor_(input, other),
torch.Tensor.bitwise_xor(input, other),
torch.Tensor.bmm(input, batch2),
torch.Tensor.bool(input, memory_format=torch.preserve_format),
torch.Tensor.broadcast_to(input, shape),
torch.Tensor.byte(input, memory_format=torch.preserve_format),
torch.Tensor.cauchy_(input, median=0, sigma=1, *, generator=None),
torch.Tensor.ceil_(input),
torch.Tensor.ceil(input),
torch.Tensor.char(input, memory_format=torch.preserve_format),
torch.Tensor.cholesky_inverse(input, upper=False),
torch.Tensor.cholesky(input, upper=False),
torch.Tensor.cholesky_solve(input, input2, upper=False),
torch.Tensor.chunk(input, chunks, dim=0),
torch.Tensor.clamp_(input, min=None, max=None),
torch.Tensor.clamp(input, min=None, max=None),
torch.Tensor.clip_(input, min=None, max=None),
torch.Tensor.clip(input, min=None, max=None),
torch.Tensor.clone(input, *, memory_format=torch.preserve_format),
torch.Tensor.conj(input),
torch.Tensor.conj_physical_(input),
torch.Tensor.conj_physical(input),
torch.Tensor.contiguous(input, memory_format=torch.contiguous_format),
torch.Tensor.copy_(input, src, non_blocking=False),
torch.Tensor.copysign_(input, other),
torch.Tensor.copysign(input, other),
torch.Tensor.corrcoef(input),
torch.Tensor.cosh_(input),
torch.Tensor.cosh(input),
torch.Tensor.cos_(input),
torch.Tensor.cos(input),
torch.Tensor.count_nonzero(input, dim=None),
torch.Tensor.cov(input, *, correction=1, fweights=None, aweights=None),
torch.Tensor.cpu(input, memory_format=torch.preserve_format),
torch.Tensor.cross(input, other, dim=-1),
torch.Tensor.cuda(input, device=None, non_blocking=False, memory_format=torch.preserve_format),
torch.Tensor.cummax(input, dim),
torch.Tensor.cummin(input, dim),
torch.Tensor.cumprod_(input, dim, dtype=None),
torch.Tensor.cumprod(input, dim, dtype=None),
torch.Tensor.cumsum_(input, dim, dtype=None),
torch.Tensor.cumsum(input, dim, dtype=None),
torch.Tensor.data_ptr(input),
torch.Tensor.deg2rad(input),
torch.Tensor.dense_dim(input),
torch.Tensor.dequantize(input),
torch.Tensor.detach_(input, ),
torch.Tensor.detach(input, ),
torch.Tensor.det(input),
torch.Tensor.device(input, ),
torch.Tensor.diag_embed(input, offset=0, dim1=-2, dim2=-1),
torch.Tensor.diagflat(input, offset=0),
torch.Tensor.diag(input, diagonal=0),
torch.Tensor.diagonal(input, offset=0, dim1=0, dim2=1),
torch.Tensor.diff(input, n=1, dim=-1, prepend=None, append=None),
torch.Tensor.digamma_(input),
torch.Tensor.digamma(input),
torch.Tensor.dim(input),
torch.Tensor.dist(input, other, p=2),
torch.Tensor.divide_(input, value, *, rounding_mode=None),
torch.Tensor.divide(input, value, *, rounding_mode=None),
torch.Tensor.div_(input, value, *, rounding_mode=None),
torch.Tensor.div(input, value, *, rounding_mode=None),
torch.tensordot(a, b, dims=2, out=None),
torch.Tensor.dot(input, other),
torch.Tensor.double(input, memory_format=torch.preserve_format),
torch.Tensor.dsplit(input, split_size_or_sections),
torch.Tensor.eig(input, eigenvectors=False),
torch.Tensor.element_size(input),
torch.Tensor.eq_(input, other),
torch.Tensor.eq(input, other),
torch.Tensor.equal(input, other),
torch.Tensor.erfc_(input),
torch.Tensor.erfc(input),
torch.Tensor.erfinv_(input),
torch.Tensor.erfinv(input),
torch.Tensor.erf_(input),
torch.Tensor.erf(input),
torch.Tensor.expand_as(input, other),
torch.Tensor.expand(input, *sizes),
torch.Tensor.exp_(input),
torch.Tensor.exp(input),
torch.Tensor.expm1_(input),
torch.Tensor.expm1(input),
torch.Tensor.exponential_(input, lambd=1, *, generator=None),
torch.Tensor.fill_diagonal_(input, fill_value, wrap=False),
torch.Tensor.fill_(input, value),
torch.Tensor.fix_(input),
torch.Tensor.fix(input),
torch.Tensor.flatten(input, start_dim=0, end_dim=-1),
torch.Tensor.flip(input, dims),
torch.Tensor.fliplr(input),
torch.Tensor.flipud(input),
torch.Tensor.float(input, memory_format=torch.preserve_format),
torch.Tensor.float_power_(input, exponent),
torch.Tensor.float_power(input, exponent),
torch.Tensor.floor_divide_(input, value),
torch.Tensor.floor_divide(input, value),
torch.Tensor.floor_(input),
torch.Tensor.floor(input),
torch.Tensor.fmax(input, other),
torch.Tensor.fmin(input, other),
torch.Tensor.fmod_(input, divisor),
torch.Tensor.fmod(input, divisor),
torch.Tensor.frac_(input),
torch.Tensor.frac(input),
torch.Tensor.frexp(input, input),
torch.Tensor.gather(input, dim, index),
torch.Tensor.gcd_(input, other),
torch.Tensor.gcd(input, other),
torch.Tensor.ge_(input, other),
torch.Tensor.ge(input, other),
torch.Tensor.geometric_(input, p, *, generator=None),
torch.Tensor.geqrf(input),
torch.Tensor.ger(input, vec2),
torch.Tensor.get_device(input),
torch.Tensor.grad(input, ),
torch.Tensor.greater_equal_(input, other),
torch.Tensor.greater_equal(input, other),
torch.Tensor.greater_(input, other),
torch.Tensor.greater(input, other),
torch.Tensor.gt_(input, other),
torch.Tensor.gt(input, other),
torch.Tensor.half(input, memory_format=torch.preserve_format),
torch.Tensor.hardshrink(input, lambd=0.5),
torch.Tensor.heaviside(input, values),
torch.Tensor.histc(input, bins=100, min=0, max=0),
torch.Tensor.histogram(input, input, bins, *, range=None, weight=None, density=False),
torch.Tensor.hsplit(input, split_size_or_sections),
torch.Tensor.hypot_(input, other),
torch.Tensor.hypot(input, other),
torch.Tensor.i0_(input),
torch.Tensor.i0(input),
torch.Tensor.igammac_(input, other),
torch.Tensor.igammac(input, other),
torch.Tensor.igamma_(input, other),
torch.Tensor.igamma(input, other),
torch.Tensor.imag(input, ),
torch.Tensor.index_add_(input, dim, index, tensor, *, alpha=1),
torch.Tensor.index_add(input, dim, index, tensor2),
torch.Tensor.index_copy_(input, dim, index, tensor),
torch.Tensor.index_copy(input, dim, index, tensor2),
torch.Tensor.index_fill_(input, dim, index, value),
torch.Tensor.index_fill(input, dim, index, value),
torch.Tensor.index_put_(input, indices, values, accumulate=False),
torch.Tensor.index_put(input, indices, values, accumulate=False),
torch.Tensor.index_select(input, dim, index),
torch.Tensor.indices(input),
torch.Tensor.inner(input, other),
torch.Tensor.int(input, memory_format=torch.preserve_format),
torch.Tensor.int_repr(input),
torch.Tensor.inverse(input),
torch.Tensor.isclose(input, other, rtol=1e-05, atol=1e-08, equal_nan=False),
torch.Tensor.is_complex(input),
torch.Tensor.is_conj(input),
torch.Tensor.is_contiguous(input, memory_format=torch.contiguous_format),
torch.Tensor.is_cuda(input, ),
torch.Tensor.isfinite(input),
torch.Tensor.is_floating_point(input),
torch.Tensor.is_inference(input),
torch.Tensor.isinf(input),
torch.Tensor.is_leaf(input, ),
torch.Tensor.is_meta(input, ),
torch.Tensor.isnan(input),
torch.Tensor.isneginf(input),
torch.Tensor.is_pinned(input, ),
torch.Tensor.isposinf(input),
torch.Tensor.is_quantized(input, ),
torch.Tensor.isreal(input),
torch.Tensor.is_set_to(input, tensor),
torch.Tensor.is_shared(input, ),
torch.Tensor.is_signed(input),
torch.Tensor.is_sparse(input, ),
torch.Tensor.istft(input, n_fft, hop_length=None, win_length=None, window=None, center=True, normalized=False, onesided=None, length=None, return_complex=False),
torch.Tensor.item(input),
torch.tensor(data, *, dtype=None, device=None, requires_grad=False, pin_memory=False),
torch.Tensor.kthvalue(input, k, dim=None, keepdim=False),
torch.Tensor.lcm_(input, other),
torch.Tensor.lcm(input, other),
torch.Tensor.ldexp_(input, other),
torch.Tensor.ldexp(input, other),
torch.Tensor.le_(input, other),
torch.Tensor.le(input, other),
torch.Tensor.lerp_(input, end, weight),
torch.Tensor.lerp(input, end, weight),
torch.Tensor.less_equal_(input, other),
torch.Tensor.less_equal(input, other),
torch.Tensor.less_(input, other),
torch.Tensor.less(input, other),
torch.Tensor.lgamma_(input),
torch.Tensor.lgamma(input),
torch.Tensor.log10_(input),
torch.Tensor.log10(input),
torch.Tensor.log1p_(input),
torch.Tensor.log1p(input),
torch.Tensor.log2_(input),
torch.Tensor.log2(input),
torch.Tensor.logaddexp2(input, other),
torch.Tensor.logaddexp(input, other),
torch.Tensor.logcumsumexp(input, dim),
torch.Tensor.logdet(input),
torch.Tensor.logical_and_(input, other),
torch.Tensor.logical_and(input, other),
torch.Tensor.logical_not_(input),
torch.Tensor.logical_not(input),
torch.Tensor.logical_or_(input, other),
torch.Tensor.logical_or(input, other),
torch.Tensor.logical_xor_(input, other),
torch.Tensor.logical_xor(input, other),
torch.Tensor.logit_(input),
torch.Tensor.logit(input),
torch.Tensor.log_(input),
torch.Tensor.log(input),
torch.Tensor.log_normal_(input, mean=1, std=2, *, generator=None),
torch.Tensor.logsumexp(input, dim, keepdim=False),
torch.Tensor.long(input, memory_format=torch.preserve_format),
torch.Tensor.lstsq(input, A),
torch.Tensor.lt_(input, other),
torch.Tensor.lt(input, other),
torch.Tensor.lu(input, pivot=True, get_infos=False),
torch.Tensor.lu_solve(input, LU_data, LU_pivots),
torch.Tensor.map_(input, tensor, callable),
torch.Tensor.masked_fill_(input, mask, value),
torch.Tensor.masked_fill(input, mask, value),
torch.Tensor.masked_scatter_(input, mask, source),
torch.Tensor.masked_scatter(input, mask, tensor),
torch.Tensor.masked_select(input, mask),
torch.Tensor.matmul(input, tensor2),
torch.Tensor.matrix_exp(input),
torch.Tensor.matrix_power(input, n),
torch.Tensor.maximum(input, other),
torch.Tensor.max(input, dim=None, keepdim=False),
torch.Tensor.mean(input, dim=None, keepdim=False, *, dtype=None),
torch.Tensor.median(input, dim=None, keepdim=False),
torch.Tensor.minimum(input, other),
torch.Tensor.min(input, dim=None, keepdim=False),
torch.Tensor.mm(input, mat2),
torch.Tensor.mode(input, dim=None, keepdim=False),
torch.Tensor.moveaxis(input, source, destination),
torch.Tensor.movedim(input, source, destination),
torch.Tensor.msort(input),
torch.Tensor.mul_(input, value),
torch.Tensor.mul(input, value),
torch.Tensor.multinomial(input, num_samples, replacement=False, *, generator=None),
torch.Tensor.multiply_(input, value),
torch.Tensor.multiply(input, value),
torch.Tensor.mv(input, vec),
torch.Tensor.mvlgamma_(input, p),
torch.Tensor.mvlgamma(input, p),
torch.Tensor.nanmean(input, dim=None, keepdim=False, *, dtype=None),
torch.Tensor.nanmedian(input, dim=None, keepdim=False),
torch.Tensor.nanquantile(input, q, dim=None, keepdim=False),
torch.Tensor.nansum(input, dim=None, keepdim=False, dtype=None),
torch.Tensor.nan_to_num_(input, nan=0.0, posinf=None, neginf=None),
torch.Tensor.nan_to_num(input, nan=0.0, posinf=None, neginf=None),
torch.Tensor.narrow_copy(input, dimension, start, length),
torch.Tensor.narrow(input, dimension, start, length),
torch.Tensor.ndimension(input),
torch.Tensor.ndim(input),
torch.Tensor.negative_(input),
torch.Tensor.negative(input),
torch.Tensor.neg_(input),
torch.Tensor.neg(input),
torch.Tensor.ne_(input, other),
torch.Tensor.ne(input, other),
torch.Tensor.nelement(input),
torch.Tensor.new_empty(input, size, dtype=None, device=None, requires_grad=False),
torch.Tensor.new_full(input, size, fill_value, dtype=None, device=None, requires_grad=False),
torch.Tensor.new_ones(input, size, dtype=None, device=None, requires_grad=False),
torch.Tensor.new_tensor(input, data, dtype=None, device=None, requires_grad=False),
torch.Tensor.new_zeros(input, size, dtype=None, device=None, requires_grad=False),
torch.Tensor.nextafter_(input, other),
torch.Tensor.nextafter(input, other),
torch.Tensor.nonzero(input, as_tuple=False),
torch.Tensor.normal_(input, mean=0, std=1, *, generator=None),
torch.Tensor.norm(input, p='fro', dim=None, keepdim=False, dtype=None),
torch.Tensor.not_equal_(input, other),
torch.Tensor.not_equal(input, other),
torch.Tensor.numel(input),
torch.Tensor.numpy(input),
torch.Tensor.orgqr(input, input2),
torch.Tensor.ormqr(input, input2, input3, left=True, transpose=False),
torch.Tensor.outer(input, vec2),
torch.Tensor.permute(input, *dims),
torch.Tensor.pin_memory(input),
torch.Tensor.pinverse(input),
torch.Tensor.polygamma_(input, n),
torch.Tensor.polygamma(input, n),
torch.Tensor.positive(input),
torch.Tensor.pow_(input, exponent),
torch.Tensor.pow(input, exponent),
torch.Tensor.prod(input, dim=None, keepdim=False, dtype=None),
torch.Tensor.put_(input, index, source, accumulate=False),
torch.Tensor.q_per_channel_axis(input),
torch.Tensor.q_per_channel_scales(input),
torch.Tensor.q_per_channel_zero_points(input),
torch.Tensor.qr(input, some=True),
torch.Tensor.q_scale(input),
torch.Tensor.qscheme(input),
torch.Tensor.quantile(input, q, dim=None, keepdim=False),
torch.Tensor.q_zero_point(input),
torch.Tensor.rad2deg(input),
torch.Tensor.random_(input, from=0, to=None, *, generator=None),
torch.Tensor.ravel(input),
torch.Tensor.real(input, ),
torch.Tensor.reciprocal_(input),
torch.Tensor.reciprocal(input),
torch.Tensor.record_stream(input, stream),
torch.Tensor.register_hook(input, hook),
torch.Tensor.remainder_(input, divisor),
torch.Tensor.remainder(input, divisor),
torch.Tensor.renorm_(input, p, dim, maxnorm),
torch.Tensor.renorm(input, p, dim, maxnorm),
torch.Tensor.repeat_interleave(input, repeats, dim=None, *, output_size=None),
torch.Tensor.repeat(input, *sizes),
torch.Tensor.requires_grad_(input, requires_grad=True),
torch.Tensor.requires_grad(input, ),
torch.Tensor.reshape_as(input, other),
torch.Tensor.reshape(input, *shape),
torch.Tensor.resize_as_(input, tensor, memory_format=torch.contiguous_format),
torch.Tensor.resize_(input, *sizes, memory_format=torch.contiguous_format),
torch.Tensor.resolve_conj(input),
torch.Tensor.resolve_neg(input),
torch.Tensor.retain_grad(input),
torch.Tensor.retains_grad(input, ),
torch.Tensor.roll(input, shifts, dims),
torch.Tensor.rot90(input, k, dims),
torch.Tensor.round_(input),
torch.Tensor.round(input),
torch.Tensor.rsqrt_(input),
torch.Tensor.rsqrt(input),
torch.Tensor.scatter_add_(input, dim, index, src),
torch.Tensor.scatter_add(input, dim, index, src),
torch.Tensor.scatter_(input, dim, index, src, reduce=None),
torch.Tensor.scatter(input, dim, index, src),
torch.Tensor.select(input, dim, index),
torch.Tensor.set_(input, source=None, storage_offset=0, size=None, stride=None),
torch.Tensor.sgn_(input),
torch.Tensor.sgn(input),
torch.Tensor.share_memory_(input, ),
torch.Tensor.short(input, memory_format=torch.preserve_format),
torch.Tensor.sigmoid_(input),
torch.Tensor.sigmoid(input),
torch.Tensor.signbit(input),
torch.Tensor.sign_(input),
torch.Tensor.sign(input),
torch.Tensor.sinc_(input),
torch.Tensor.sinc(input),
torch.Tensor.sinh_(input),
torch.Tensor.sinh(input),
torch.Tensor.sin_(input),
torch.Tensor.sin(input),
torch.Tensor.size(input, dim=None),
torch.Tensor.slogdet(input),
torch.Tensor.smm(input, mat),
torch.Tensor.solve(input, A),
torch.Tensor.sort(input, dim=-1, descending=False),
torch.Tensor.sparse_dim(input),
torch.Tensor.sparse_mask(input, mask),
torch.tensor_split(input, indices_or_sections, dim=0),
torch.Tensor.split(input, split_size, dim=0),
torch.Tensor.sqrt_(input),
torch.Tensor.sqrt(input),
torch.Tensor.square_(input),
torch.Tensor.square(input),
torch.Tensor.squeeze_(input, dim=None),
torch.Tensor.squeeze(input, dim=None),
torch.Tensor.sspaddmm(input, mat1, mat2, *, beta=1, alpha=1),
torch.Tensor.std(input, dim, unbiased=True, keepdim=False),
torch.Tensor.stft(input, n_fft, hop_length=None, win_length=None, window=None, center=True, pad_mode='reflect', normalized=False, onesided=None, return_complex=None),
torch.Tensor.storage(input),
torch.Tensor.storage_offset(input),
torch.Tensor.storage_type(input),
torch.Tensor.stride(input, dim),
torch.Tensor.sub_(input, other, *, alpha=1),
torch.Tensor.sub(input, other, *, alpha=1),
torch.Tensor.subtract_(input, other, *, alpha=1),
torch.Tensor.subtract(input, other, *, alpha=1),
torch.Tensor.sum(input, dim=None, keepdim=False, dtype=None),
torch.Tensor.sum_to_size(input, *size),
torch.Tensor.svd(input, some=True, compute_uv=True),
torch.Tensor.swapaxes(input, axis0, axis1),
torch.Tensor.swapdims(input, dim0, dim1),
torch.Tensor.symeig(input, eigenvectors=False, upper=True),
torch.Tensor.take_along_dim(input, indices, dim),
torch.Tensor.take(input, indices),
torch.Tensor.tanh_(input),
torch.Tensor.tanh(input),
torch.Tensor.tan_(input),
torch.Tensor.tan(input),
torch.Tensor.tensor_split(input, indices_or_sections, dim=0),
torch.Tensor.tile(input, dims),
torch.Tensor.t_(input),
torch.Tensor.t(input),
torch.Tensor.to(input, *args, **kwargs),
torch.Tensor.tolist(input),
torch.Tensor.to_mkldnn(input),
torch.Tensor.topk(input, k, dim=None, largest=True, sorted=True),
torch.Tensor.to_sparse(input, sparseDims),
torch.Tensor.trace(input),
torch.Tensor.transpose_(input, dim0, dim1),
torch.Tensor.transpose(input, dim0, dim1),
torch.Tensor.triangular_solve(input, A, upper=True, transpose=False, unitriangular=False),
torch.Tensor.tril_(input, diagonal=0),
torch.Tensor.tril(input, diagonal=0),
torch.Tensor.triu_(input, diagonal=0),
torch.Tensor.triu(input, diagonal=0),
torch.Tensor.true_divide_(input, value),
torch.Tensor.true_divide(input, value),
torch.Tensor.trunc_(input),
torch.Tensor.trunc(input),
torch.Tensor.type_as(input, tensor),
torch.Tensor.type(input, dtype=None, non_blocking=False, **kwargs),
torch.Tensor.unbind(input, dim=0),
torch.Tensor.unfold(input, dimension, size, step),
torch.Tensor.uniform_(input, from=0, to=1),
torch.Tensor.unique_consecutive(input, return_inverse=False, return_counts=False, dim=None),
torch.Tensor.unique(input, sorted=True, return_inverse=False, return_counts=False, dim=None),
torch.Tensor.unsqueeze_(input, dim),
torch.Tensor.unsqueeze(input, dim),
torch.Tensor.values(input),
torch.Tensor.var(input, dim, unbiased=True, keepdim=False),
torch.Tensor.vdot(input, other),
torch.Tensor.view_as(input, other),
torch.Tensor.view(input, *shape),
torch.Tensor.vsplit(input, split_size_or_sections),
torch.Tensor.where(input, condition, y),
torch.Tensor.xlogy_(input, other),
torch.Tensor.xlogy(input, other),
torch.Tensor.zero_(input),
torch.testing.assert_close(actual, expected, *, allow_subclasses=True, rtol=None, atol=None, equal_nan=False, check_device=True, check_dtype=True, check_stride=False, check_is_coalesced=True, msg=None),
torch.testing.make_tensor(shape, device, dtype, *, low=None, high=None, requires_grad=False, noncontiguous=False, exclude_zero=False),
torch.tile(input, dims),
torch.t(input),
torch.topk(input, k, dim=None, largest=True, sorted=True, *, out=None),
torch.trace(input),
torch.transpose(input, dim0, dim1),
torch.trapezoid(y, x=None, *, dx=None, dim=- 1),
torch.trapz(y, x, *, dim=-1),
torch.triangular_solve(b, A, upper=True, transpose=False, unitriangular=False),
torch.tril_indices(row, col, offset=0, *, dtype=torch.long, device='cpu', layout=torch.strided),
torch.tril(input, diagonal=0, *, out=None),
torch.triu_indices(row, col, offset=0, *, dtype=torch.long, device='cpu', layout=torch.strided),
torch.triu(input, diagonal=0, *, out=None),
torch.true_divide(dividend, divisor, *, out),
torch.trunc(input, *, out=None),
torch.unbind(input, dim=0),
torch.unique_consecutive(input, return_inverse=False, return_counts=False, dim=None),
torch.unique(input, sorted=True, return_inverse=False, return_counts=False, dim=None),
torch.unsqueeze(input, dim),
torch.use_deterministic_algorithms(mode),
torch.vander(x, N=None, increasing=False),
torch.var(input, dim, unbiased, keepdim=False, *, out=None),
torch.var_mean(input, dim, unbiased, keepdim=False, *, out=None),
torch.vdot(input, other, *, out=None),
torch.view_as_complex(input),
torch.view_as_real(input),
torch.vsplit(input, indices_or_sections),
torch.vstack(tensors, *, out=None),
torch.where(condition, x, y),
torch.xlogy(input, other, *, out=None),
torch.zeros(*size, *, out=None, dtype=None, layout=torch.strided, device=None, requires_grad=False),
torch.zeros_like(input, *, dtype=None, layout=None, device=None, requires_grad=False, memory_format=torch.preserve_format)